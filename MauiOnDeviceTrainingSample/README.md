# On-Device Training Sample (MAUI + Android + LiteRT)

This zip contains:

- **MauiOnDeviceTraining/** ‚Äì .NET MAUI Android app (UI: camera, collect samples, Train/Infer buttons)
- **AndroidTrainingLib/** ‚Äì Android Studio Kotlin library that performs **on-device training** using **LiteRT (TensorFlow Lite)** APIs, exported as an **AAR** and called from MAUI via JNI.

## Why LiteRT (TensorFlow Lite)?
- Google supports **on-device training** on Android by exporting multiple **signatures** (e.g., `train`, `infer`, `save`, `restore`) in a `.tflite` model.  
  See the official guide and tutorial: https://ai.google.dev/edge/litert/conversion/tensorflow/build/ondevice_training  
- TensorFlow‚Äôs blog introduced on-device training support in TF 2.7+ and shows end‚Äëto‚Äëend Android examples: https://blog.tensorflow.org/2021/11/on-device-training-in-tensorflow-lite.html  

**Note:** ONNX Runtime Mobile supports **inference** on Android but **not training**. Use LiteRT for training on phone; keep MAUI as the UI shell.

## How to use
1. Open **AndroidTrainingLib/** in **Android Studio** and build the AAR in Release.
2. Copy the AAR to `MauiOnDeviceTraining/libs/` and uncomment the `<AndroidLibrary>` entry in the MAUI `.csproj`.
3. Ensure your training-enabled `.tflite` path is provided to `Trainer.configureModelPath(...)` (you can call this via an additional JNI method or set it once from MAUI).
4. Build & deploy the MAUI app to an Android device:
   ```bash
   dotnet build -t:Run -f net8.0-android
   ```

## Limitations
- Phone training is feasible for **transfer learning** or **small models**; avoid full end‚Äëto‚Äëend training for large nets.
- Shipping `.tflite` with training ops can increase size; consider downloading it after license/activation.

## Security
- If you sell models, encrypt them, decrypt in memory, and use Android Keystore for key protection. True DRM is not possible on a fully local model, but you can raise the barrier with in‚Äëmemory decryption and obfuscation.


# üì± Maui On‚ÄëDevice Training Sample

A .NET MAUI (Android) app that lets you:

- **Capture** images from the device **camera**  
- **Collect** them as a small dataset on the phone  
- **Train** an on‚Äëdevice model (via a native Android library)  
- **Infer** with the updated model‚Äîall **on the phone**, no cloud required

> The MAUI UI (C#) handles camera preview, capture, and buttons.  
> A native Android library (Kotlin) performs the actual on‚Äëdevice training and inference (LiteRT / TensorFlow Lite).

---

## ‚ú® Features

- **Camera preview & capture** using CommunityToolkit `CameraView`
- **Dataset builder**: save captured frames to the app‚Äôs local storage
- **On‚Äëdevice training**: fine‚Äëtune a **training‚Äëenabled** `.tflite` model with your captured samples
- **Inference**: run predictions with the updated model and display the result
- **Android‚Äëonly** (for training): MAUI provides the cross‚Äëplatform shell; the training/ML execution is Android‚Äënative

---

## üß± Architecture

```
MauiOnDeviceTrainingSample/
‚îÇ
‚îú‚îÄ MauiOnDeviceTraining/          # .NET MAUI app (UI shell)
‚îÇ  ‚îú‚îÄ MainPage.xaml(.cs)          # Camera preview, capture, Train, Infer
‚îÇ  ‚îú‚îÄ Services/Trainer.cs         # JNI bridge to AndroidTrainingLib (AAR)
‚îÇ  ‚îú‚îÄ Resources/Models/           # (optional) seed .tflite files
‚îÇ  ‚îú‚îÄ Resources/Dataset/          # runtime dataset (captured images)
‚îÇ  ‚îî‚îÄ Platforms/Android/          # Android manifest & libs
‚îÇ
‚îî‚îÄ AndroidTrainingLib/            # Android Studio library (Kotlin)
   ‚îú‚îÄ build.gradle                # depends on LiteRT/TensorFlow Lite
   ‚îú‚îÄ src/.../Trainer.kt          # train() & infer() signatures
   ‚îî‚îÄ (AAR output for MAUI)
```

- **MAUI** (C#): presents UI, uses `CameraView`, saves images, and calls the Kotlin library via **JNI**.
- **AndroidTrainingLib** (Kotlin): loads a **training‚Äëenabled `.tflite`** and executes **`train`** / **`infer`** signatures.

---

## üß© What is a ‚Äútraining‚Äëenabled‚Äù `.tflite`?

Your model must be exported with multiple **signatures**, typically:

- `train` ‚Äî updates weights using your examples  
- `infer` ‚Äî runs forward pass and outputs scores/labels  
- `save` / `restore` ‚Äî optional, to persist updated weights

You‚Äôll point the Android library at this `.tflite` file. The library handles preprocessing (e.g., resizing to 224√ó224, normalization) and calls the proper signatures during **Train** and **Infer**.

> **Tip:** Use transfer learning (e.g., train only the final layers) to keep training fast on phones.

---

## ‚ñ∂Ô∏è Running the App (Android)

1. **Build the Android training library (AAR)**  
   Open `AndroidTrainingLib/` in **Android Studio** and build **Release** ‚Üí produces `AndroidTrainingLib-release.aar`.

2. **Add AAR to MAUI**  
   Copy the AAR to `MauiOnDeviceTraining/libs/` and in `MauiOnDeviceTraining.csproj` **uncomment** the line:
   ```xml
   <AndroidLibrary Include="libs/AndroidTrainingLib-release.aar" />
   ```

3. **Deploy MAUI to your device**
   ```bash
   dotnet build -t:Run -f net8.0-android
   ```

4. **Use the app**  
   - Toggle **Camera** ‚Üí preview starts (permission prompt on first run)  
   - Tap **Capture sample** ‚Üí image is saved to the dataset  
   - Tap **Train on device** ‚Üí the Kotlin library runs the `train` signature  
   - Tap **Infer (trained)** ‚Üí runs `infer` on a new frame and shows the result

---

## ‚öôÔ∏è Configuration

- **Model path**  
  Provide your `.tflite` to the Android library (e.g., via a config method or by placing it in app storage). The Kotlin side expects a **valid path** to the training‚Äëenabled `.tflite`.

- **Preprocessing**  
  Default: **224√ó224** RGB with ImageNet‚Äëstyle normalization. If your model expects different size/mean/std, adjust it in the Android library.

- **Labels**  
  If you use class labels (e.g., `ripe`, `unripe`, `overripe`), keep a consistent mapping between the MAUI UI and the Kotlin one‚Äëhot/decoding logic.

---

## üîê Shipping / Security notes

If you plan to **sell models** or ship paid content:

- **Encrypt** your `.tflite`, **decrypt in memory** only  
- Store/derive keys with **Android Keystore**  
- Obfuscate the native loader / split keys  
- Optionally **download** the model post‚Äëlicense check

> No local protection is absolute, but these steps raise the barrier.

---

## üß™ Testing checklist

- Camera permission granted and preview starts/stops cleanly  
- At least a few samples captured before training  
- Training runs for the configured epochs without exceptions  
- Inference after training shows a sensible label/score  
- Model path and tensor names match your exported signatures

---

## üöÄ Extending

- **Continuous training**: add a small scheduler to retrain after N new samples  
- **Live classification**: add timed captures during preview (throttled)  
- **Bounding boxes / segmentation**: adapt model + overlay drawing  
- **Model packs**: download model archives + labels at first launch  
- **Telemetry**: log time per epoch, accuracy, loss

---

## üß† Summary

This sample demonstrates a practical pattern for **on‚Äëdevice model personalization**:

- MAUI provides a familiar C# UI and camera integration  
- A native Android library performs **real training** (update weights) and **inference**  
- The phone can learn from the user‚Äôs data locally‚Äîno uploads needed

